{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        },
        {
            "name": "Train model - Local debugging - with wandb",
            "type": "debugpy",
            "request": "launch",
            "program": "grokking/scripts/train_grokk.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "args": [
                "dataset.dataset_seed=42",
                //
                "dataset.frac_train=0.4",
                //
                "train.weight_decay=0.01",
                //
                "wandb.use_wandb=true",
                "wandb.wandb_project=grokking_replica_debugging",
            ],
        },
        {
            "name": "Train model - Local debugging - offline mode with wandb",
            "type": "debugpy",
            "request": "launch",
            "program": "grokking/scripts/train_grokk.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "args": [
                "dataset.dataset_seed=42",
                //
                "dataset.frac_train=0.4",
                //
                "wandb.use_wandb=true",
                "wandb.wandb_project=grokking_replica_debugging",
            ],
            "env": {
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Train model - Local debugging - default settings - mod_subtract_dataset - without wandb",
            "type": "debugpy",
            "request": "launch",
            "program": "grokking/scripts/train_grokk.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "args": [
                "dataset.dataset_seed=42",
                //
                "dataset.frac_train=0.4",
                //
                "train.weight_decay=0.0",
                //
                "wandb.use_wandb=false",
                "wandb.wandb_project=grokking_replica_debugging", // <-- not relevant for running without wandb
            ],
            "env": {
                "WANDB_DISABLED": "true"
            }
        },
        {
            "name": "Train model - Local debugging - multirun - without wandb",
            "type": "debugpy",
            "request": "launch",
            "program": "grokking/scripts/train_grokk.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "args": [
                "--multirun",
                "hydra/launcher=basic",
                // "hydra/launcher=joblib", // <-- Note: Currently, the joblib launcher is not working locally.
                //
                "dataset.frac_train=0.4",
                //
                "train.weight_decay=0.01",
                //
                "wandb.use_wandb=false",
                "wandb.wandb_project=grokking_replica_debugging", // <-- not relevant for running without wandb
            ],
            "env": {
                "WANDB_DISABLED": "true"
            }
        },
        // Note: Even though this page claims that the maximum duration of a GPU-Job is 47:59:59, we can sucessfully submit jobs with a duration of 59:00:00.
        // https://wiki.hhu.de/display/HPC/Besonderheiten
        {
            "name": "Train model - HHU Hilbert HPC submission - Single Setup - without wandb",
            "type": "debugpy",
            "request": "launch",
            "program": "grokking/scripts/train_grokk.py",
            "console": "integratedTerminal",
            "args": [
                //    >> START: Hydra options
                "--multirun",
                "hydra/sweeper=basic",
                "hydra/launcher=hpc_submission", // <-- Use this for HHU Hilbert HPC submission
                "hydra.launcher.queue=CUDA",
                // "hydra.launcher.template=RTX6000",
                // "hydra.launcher.template=GTX1080",
                // TODO: Add options for DSML queue
                "hydra.launcher.memory=32",
                "hydra.launcher.ncpus=4",
                "hydra.launcher.ngpus=1",
                "hydra.launcher.walltime=59:00:00", // <-- We choose to run the training for long enough so that we can get up to ... global steps.
                //    >> END: Hydra options
                //
                "dataset.dataset_seed=42",
                //
                "dataset.frac_train=0.4",
                //
                "train.weight_decay=0.01",
                //
                "wandb.use_wandb=false",
                "wandb.wandb_project=without_wandb",
            ],
            "env": {
                "WANDB_DISABLED": "true",
                "PYTORCH_ENABLE_MPS_FALLBACK": "1"
            }
        },
        {
            "name": "Train model - HHU Hilbert HPC submission - Single Setup - with wandb",
            "type": "debugpy",
            "request": "launch",
            "program": "grokking/scripts/train_grokk.py",
            "console": "integratedTerminal",
            "args": [
                //    >> START: Hydra options
                "--multirun",
                "hydra/sweeper=basic",
                // "hydra/launcher=basic", // <-- Use this for local submission
                "hydra/launcher=hpc_submission", // <-- Use this for HHU Hilbert HPC submission
                "hydra.launcher.queue=CUDA",
                // "hydra.launcher.template=RTX6000",
                "hydra.launcher.template=GTX1080",
                "hydra.launcher.memory=32",
                "hydra.launcher.ncpus=4",
                "hydra.launcher.ngpus=1",
                "hydra.launcher.walltime=59:00:00", // <-- We choose to run the training for long enough so that we can get up to ... global steps.
                //    >> END: Hydra options
                //
                "dataset.dataset_seed=42",
                //
                "dataset.frac_train=0.4",
                //
                "wandb.use_wandb=true",
                "wandb.wandb_project=grokking_replica_HHU_Hilbert_HPC_runs",
            ],
            "env": {
                "PYTORCH_ENABLE_MPS_FALLBACK": "1"
            }
        },
        {
            "name": "Train model - HHU Hilbert HPC submission - Multiple dataset seeds",
            "type": "debugpy",
            "request": "launch",
            "program": "grokking/scripts/train_grokk.py",
            "console": "integratedTerminal",
            "args": [
                //    >> START: Hydra options
                "--multirun",
                "hydra/sweeper=basic",
                // "hydra/launcher=basic", // <-- Use this for local submission
                "hydra/launcher=hpc_submission", // <-- Use this for HHU Hilbert HPC submission
                "hydra.launcher.queue=CUDA",
                // "hydra.launcher.template=RTX6000",
                "hydra.launcher.template=GTX1080",
                "hydra.launcher.memory=32",
                "hydra.launcher.ncpus=4",
                "hydra.launcher.ngpus=1",
                "hydra.launcher.walltime=59:00:00", // <-- We choose to run the training for long enough so that we can get up to ... global steps.
                //    >> END: Hydra options
                //
                // "dataset.dataset_seed=42",
                // "dataset.dataset_seed=43,44", // <-- Two additional seeds
                "dataset.dataset_seed=43,44,45,46", // <-- Four additional seeds
                // "dataset.dataset_seed=42,43,44,45,46", // <-- Five seeds
                //
                "dataset.frac_train=0.4",
                //
                "train.weight_decay=0.01",
                //
                "wandb.use_wandb=true",
                "wandb.wandb_project=grokking_replica_HHU_Hilbert_HPC_runs",
            ],
            "env": {
                "PYTORCH_ENABLE_MPS_FALLBACK": "1"
            }
        },
    ]
}